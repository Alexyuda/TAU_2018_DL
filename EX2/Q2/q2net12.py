# -*- coding: utf-8 -*-
"""Q2Net12v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GakfdRgRW0e7xymq1kCcyhATjWU64LoX
"""
import torch
import torchfile
import numpy as np
from matplotlib import pyplot as plt
from sklearn.feature_extraction import image
import matplotlib.image as mpimg
from torch.utils.data import Dataset,DataLoader
from torchsummary import summary
import torch.optim as optim
from PIL import Image
from skimage import transform
import cv2

runOnGdrive = False

if runOnGdrive:
	from google.colab import drive
	drive.mount('/content/drive/')

	!pip3 install torch torchvision torchfile torchsummary pillow
	!pip3 uninstall Pillow -y
	!pip3 install Pillow==4.1.1

# get dataset
data_main = "drive/My Drive/Colab Notebooks/TAU_2018_DL/HW2/EX2_data"

downloadData = False
if downloadData:
  !wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar -P drive/My\ Drive/Colab\ Notebooks/TAU_2018_DL/HW2/EX2_data
  !mkdir drive/My\ Drive/Colab\ Notebooks/TAU_2018_DL/HW2/EX2_data/VOC2007
  !tar -xf data_main/VOCtrainval_06-Nov-2007.tar -C drive/My\ Drive/Colab\ Notebooks/TAU_2018_DL/HW2/EX2_data/VOC2007
  !rm -rf drive/My\ Drive/Colab\ Notebooks/TAU_2018_DL/HW2/EX2_data/VOC2007/VOCtrainval_06-Nov-2007.tar


class View(torch.nn.Module):
    def forward(self, x):
        x = x.view(x.size()[0], -1)
        return x

use_cuda = torch.cuda.is_available()

# set FCN 
net = torch.nn.Sequential(
          torch.nn.Conv2d(3, 16, 3, stride=1, padding = 6),
          torch.nn.MaxPool2d(3, stride=2),
          torch.nn.ReLU(),
          torch.nn.Conv2d(16, 16, 4),
          torch.nn.ReLU(),
          torch.nn.Conv2d(16, 2, 1),
        )

if use_cuda:
    net.cuda()
    print("using cuda!")

# load pre-trained weights
modelPath = data_main + "/12net.pth"
pre_trained_model=torch.load(modelPath)

net[0].weight = pre_trained_model[0].weight
net[0].bias = pre_trained_model[0].bias
fc4 = pre_trained_model[4].state_dict()
net[3].load_state_dict({"weight":fc4["weight"].view(16, 16, 4, 4), "bias":fc4["bias"]})
fc6 = pre_trained_model[6].state_dict()
net[5].load_state_dict({"weight":fc6["weight"].view(2, 16, 1, 1), "bias":fc6["bias"]})

data_main = "drive/My Drive/Colab Notebooks/TAU_2018_DL/HW2/EX2_data"
data_aflw = data_main + "/aflw/aflw_12.t7"
data_pascal_imgs =  data_main + "/VOC2007/VOCdevkit/VOC2007/JPEGImages/"
data_pascal_personIdx =  data_main + "/VOC2007/VOCdevkit/VOC2007/ImageSets/Main/person_train.txt"

# load pascal data
personDir = data_pascal_personIdx #"D:/TAU/EX2/EX2_data/VOC2007/ImageSets/Main/person_train.txt"
pascalDir = data_pascal_imgs #"D:/TAU/EX2/EX2_data/VOC2007/JPEGImages/"



# load an image with a person
myarray = np.loadtxt(personDir)
myarray_new = np.zeros(myarray.shape[0])
j = 0
for i,line in enumerate(myarray):
  if (line[1] == 1):
    myarray_new[j] = line[0]
    j += 1
  pos_file_array  = myarray_new[:j]

nSamples = len(pos_file_array)

# create figure
fig = plt.figure(figsize=(12, 24))
rszScale = 0.25

sampleID = 103#np.random.randint(nSamples) # a nice result is for sampleID = 103
# load image and resize
filename = str(int(pos_file_array[sampleID])).zfill(6) + '.jpg'
img = mpimg.imread(pascalDir + filename)/255
img_resized = transform.resize(img, (int(img.shape[0]* rszScale), int(img.shape[1]* rszScale)))
# show image 
ax = fig.add_subplot(1, 2, 1, xticks=[], yticks=[])
ax.imshow(img_resized)
# run in net
img_resizedForNet = np.moveaxis(img_resized, -1, 0)
curImgCuda = torch.Tensor(img_resizedForNet).float().cuda()
y_val = net(curImgCuda.unsqueeze_(0))
# turn into heat map
y_val = torch.squeeze(y_val)
heatMap = y_val.cpu().data.numpy()
heatMap = np.moveaxis(heatMap, 0, -1)
heatMap1C = heatMap[:,:,0]
# show heat map
ax = fig.add_subplot(1, 2, 2, xticks=[], yticks=[])
heatPlt = ax.imshow(heatMap1C, cmap="jet_r")
plt.colorbar(heatPlt,ax=ax,fraction=0.046, pad=0.04)

def drawBoxes(heatmap, imgOrigin, wh, winHalfSize = 6):
  img = imgOrigin.copy()
  img = 255 * img # Now scale by 255
  img = img.astype(np.uint8)
  count = 0 
  for i in range(0, heatmap.shape[0]):
    for j in range(0, heatmap.shape[1]):
      if (heatmap[i, j, 0] > heatmap[i, j, 1]):
        
        count = count + 1
        
        # locations in image
        row = int(wh * i - 2)
        col = int(wh * j - 2)
        xLeft = np.maximum(0, col - winHalfSize)
        yTop = np.maximum(0, row - winHalfSize)
        xRight = np.minimum(imgOrigin.shape[1], col + winHalfSize)
        yBtm = np.minimum(imgOrigin.shape[0], row + winHalfSize)
        img = cv2.rectangle(img, (xLeft, yTop), (xRight, yBtm), (0, 255, 0), 1)

        img[int(wh * i - 2), int(wh * j - 2), 0] = 255;
        img[int(wh * i - 2), int(wh * j - 2), 1] = 0;
        img[int(wh * i - 2), int(wh * j - 2), 2] = 0;
 
  print(count)
  return img 
  

# draw rectangles around faces
sampleID = 103
heatStride = 2
# create figure
fig = plt.figure(figsize=(12, 24))
rszScale = 0.25

# load image and resize
filename = str(int(pos_file_array[sampleID])).zfill(6) + '.jpg'
img = mpimg.imread(pascalDir + filename)/255
img_resized = transform.resize(img, (int(img.shape[0]* rszScale), int(img.shape[1]* rszScale)))
# show image 
ax = fig.add_subplot(1, 2, 1, xticks=[], yticks=[])
ax.imshow(img_resized)

img_resized_forNet = np.moveaxis(img_resized, -1, 0)

curImgCuda = torch.Tensor(img_resized_forNet).float().cuda()

y_val = net(curImgCuda.unsqueeze_(0))
print(y_val.shape)
print(img_resized.shape)
# turn into heat map
y_val = torch.squeeze(y_val)
heatMap = y_val.cpu().data.numpy()
heatMap = np.moveaxis(heatMap, 0, -1)

img_colored = drawBoxes(heatMap, img_resized, heatStride)
# show heat map
ax = fig.add_subplot(1, 2, 2, xticks=[], yticks=[])
heatPlt = ax.imshow(img_colored)